# -*- coding: utf-8 -*-
"""CreditCardFraud.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RB76LtKdWNvCpp1cwARRYrY3l0pX1-ot

# Credit Card Fraud Detection using Random Forest Classifier
## M. Qasim Khan

# To do:
1. We will be using a dataset by the name **creditcard.csv** to check the number of fradulent transactions  

2. We will be using the Random Forest Classifier to perform this task

# Setup
"""

# First we will be importing the required libraries to perforn our task
from matplotlib import pyplot as plt  # importing for data visualization
from matplotlib import gridspec       # importing for data visualization
import numpy as np                    # for data processing
import pandas as pd                   # for data processing
import seaborn as sns                 # for data analysis

"""## Part 01 - Loading the Credit Card Dataset

We are using urllib to retrieve data from the given link and then create a folder which will store the csv file.
"""

# We are loading the data into a pandas dataframe
# The data is read from the csv file
cards_data = pd.read_csv('creditcard.csv')

"""## Exploratory Data Analysis

After downloading the csv file, let's observe the data and try to understandÂ what it means.
"""

# We now have a look at the head of the dataframe  
cards_data.head()

# Now we will plot the distrinution of our scores to see what their relation is like
print(cards_data.shape)
print(cards_data.describe())

# Here we will be separating the data based on class value to identify how many are frauds and how many are valid
fraud=cards_data[cards_data['Class']==1] # here we denote class value of 1 for fraudulent transactions
valid=cards_data[cards_data['Class']==0] # here we denote class value of 0 for valid transactions
outlierFraction = len(fraud)/float(len(valid)) # here we calculate the ratio of fraud to valid cases
print(outlierFraction) # displaying the above calculated ratio
print('Fraud Cases: {}'.format(len(cards_data[cards_data['Class']==1]))) # here we display the number of fraud cases 
print('Valid Transactions: {}'.format(len(cards_data[cards_data['Class']==0]))) # here we display the number of valid cases

"""We can see that we have 0.17% cases that are fraudulent. This means the data is highly unbalanced.

We will apply our model to this without balancing, and then check if the accuracy is good or not. If not good then we will balance it. 
"""

print("Amount details of the fradulent transactions")
fraud.Amount.describe()

print("Amount details of the valid transactions")
valid.Amount.describe()

corr_matrix=cards_data.corr()
Figure=plt.figure(figsize=(12,9))
sns.heatmap(corr_matrix,vmax=.8,square=True)
plt.show()

"""In the HeatMap we can clearly see that most of the features do not correlate to other features. However there are some features that either have a positive or a negative correlation with each other. For example:  

1.   V2 and V5 are highly negatively correlated with the feature called Amount
2.   We also see some correlation with V20 and Amount

This gives us a deeper understanding of the data available to us.

## Part 02 - Train Test Split
"""

X = cards_data.drop(['Class'],axis=1)
Y = cards_data['Class']
print(X.shape)
print(Y.shape)
x_Data=X.values
y_Data=Y.values

from sklearn.model_selection import train_test_split
xTrain,xTest,yTrain,yTest=train_test_split(x_Data,y_Data,test_size=0.2,random_state=42)

"""## Part 03 - Training the model

Here we will be training the model on the train sets we got from train test split
"""

from sklearn.ensemble import RandomForestClassifier  
forest = RandomForestClassifier()  
forest.fit(xTrain, yTrain) 
print("Training complete.")
y_pred=forest.predict(xTest)

# Plotting the regression line
from sklearn .metrics import classification_report, accuracy_score
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import f1_score, matthews_corrcoef
from sklearn.metrics import confusion_matrix

no_of_outliers=len(fraud)
no_of_errors=(y_pred!=yTest).sum()
print("The model is Random Forest Classifier")

Accuracy=accuracy_score(yTest,y_pred)
print("The accuracy is {}".format(Accuracy))

precision=precision_score(yTest,y_pred)
print("The precision is {}".format(precision))

Recall = recall_score(yTest, y_pred)
print("The recall is {}".format(Recall))
  
f1 = f1_score(yTest, y_pred)
print("The F1-Score is {}".format(f1))
  
MCC = matthews_corrcoef(yTest, y_pred)
print("The Matthews correlation coefficient is{}".format(MCC))

"""## Part 05 - Confusion Matrix"""

LABELS = ['Normal', 'Fraud']
conf_matrix = confusion_matrix(yTest, y_pred)
plt.figure(figsize =(12, 12))
sns.heatmap(conf_matrix, xticklabels = LABELS, 
            yticklabels = LABELS, annot = True, fmt ="d");
plt.title("Confusion matrix")
plt.ylabel('True class')
plt.xlabel('Predicted class')
plt.show()